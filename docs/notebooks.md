# Working with notebooks

While working on a research project,
Jupyter notebooks can be useful for prototyping and data exploration.
If while working interactively in a notebook
you get an output you like, e.g., a figure,
it can be tempting to simply stop right there,
save the figure,
and copy it into a research article.
However, that is not reproducible, since by definition, reproducibility means
we need to be able to go from raw data to research article with a single
command.

This is the primary notebook use case Calkit is concerned with:
generating evidence to back up conclusions or answers to research questions.
There are other use cases that are out of scope like using notebooks to build
documentation or interactive web apps for exploring results.
For building [apps](apps.md) (a different concept in a Calkit project),
there are probably better tools out there, e.g.,
[marimo](https://marimo.io/),
[Dash](https://dash.plotly.com/),
[Voila](https://voila.readthedocs.io/en/stable/),
or [Gradio](https://www.gradio.app/).

TODO: prototyping software is generating evidence.

Here we'll talk about how to take advantage of the interactive nature
of Jupyter notebooks while incorporating them into a reproducible workflow,
avoiding some of the pitfalls that have caused a bit of a
[notebook reproducibility crisis](https://leomurta.github.io/papers/pimentel2019a.pdf).
Returning to the "single command" requirement for reproducibility,
we can focus on three rules:

1. The notebook must be kept in version control, ideally with its outputs
   removed. This can be done by installing `nbstripout` and running
   `nbstripout --install` in the project directory.
1. A notebook must run in one of the project's [environments](environments.md).
1. Notebooks should be incorporated into the project's
   [pipeline](pipeline/index.md), notebooks are no exception.
   It's fine to do some ad hoc work interactively to get the notebook
   working properly, but
   "official" outputs should be generated by calling `calkit run`.
   This means notebooks need to be able to run from top-to-bottom with no
   manual intervention. We'll see how below.

Jupyter notebooks are great for prototyping and data exploration,
but can also be useful in generating evidence to support answers to
research questions.
In fact, for software prototyping, an executed notebook can be evidence
itself---evidence that answers questions regarding an idea's feasibility,
scalability, performance, etc.
In research projects, typically data and results may be explored interactively
in a notebook, with some figures and tables saved to be included in
a PDF of a research article.

So, here we're talking about using notebooks to generate
evidence to support research conclusions.
Calkit seeks to make it easier to incorporate notebooks into a
reproducible research project.

TODO: Talk about when and how to do interactive work.
For example, if you need to tweak a figure,
you can keep tweaking the cell that generates the figure,
but you'll want to ensure the version used in the paper is generated
with the pipeline.
That's reproducibility.

## Creating an environment for a notebook

Assuming you want to run Python in the notebook, you can create an environment
for it with `uv`, `venv`, `conda`, or `pixi`.
For example, if we wanted to create a new `uv-venv` called `py` in our project,
we can execute:

```sh
calkit new uv-venv \
    --name py \
    --prefix .venv \
    --python 3.13 \
    --path requirements.txt \
    jupyter \
    "pandas>=2" \
    numpy \
    plotly \
    matplotlib \
    polars
```

You can then start JupyterLab in this environment with
`calkit xenv -n py jupyter lab`, or execute the entire notebook
with `calkit nb execute -e py path/to/the/notebook.ipynb`.

Note the environment only need to be created once per project.
If the project is cloned onto a new machine,
the environment does not need to be recreated,
since that will be done automatically when the project is run.

## Adding a notebook to the pipeline

A notebook can be added to the pipeline by editing the project's `calkit.yaml`
file directly, using a `jupyter-notebook` stage.
For example:

```yaml
# In calkit.yaml
environments:
  py:
    kind: uv-venv
    prefix: .venv
    python: "3.13"
    path: requirements.txt
pipeline:
  stages:
    my-notebook:
      kind: jupyter-notebook
      environment: py
      notebook_path: notebooks/get-data.ipynb
      inputs:
        - config/my-params.json
      outputs:
        - data/raw/data.csv
      html_storage: dvc
      executed_ipynb_storage: null
      cleaned_ipynb_storage: git
# Optional: Add to project notebooks so they can be viewed on Calkit Cloud
notebooks:
  - path: notebooks/get-data.ipynb
    title: Get data
    stage: my-notebook
```

For this example, we're declaring that the notebook will read an input
file `config/my-params.json` and will produce an output
file at `data/raw/data.csv`.
These inputs and outputs will be tracked
along with the notebook and environment content,
to automatically determine if and when the notebook needs to be rerun.
Outputs will also be kept in DVC by default so others can pull them down
without bloating the Git repo.
Output storage is configurable, however, e.g., if you'd like to keep
smaller and/or text-based outputs in Git for simplicity's sake.

It's also possible to add a notebook to the pipeline
inside a notebook with the `declare_notebook` function,
which will update `calkit.yaml` automatically.

```python
import calkit

calkit.declare_notebook(
    path="notebooks/get-data.ipynb",
    stage_name="my-notebook",
    environment_name="py",
    inputs=["config/my-params.json"],
    outputs=["data/raw/data.csv"],
    html_storage="dvc",
    executed_ipynb_storage=None,
    cleaned_ipynb_storage="git",
)
```

Note that for this to run properly `calkit-python` must be installed in
the notebook's environment, which in this case is named `py` and whose
packages are listed in `requirements.txt`.
If we didn't include them when creating the environment,
we can simply add `calkit-python` to the `requirements.txt` file and rerun
`calkit xenv -n py jupyter lab`.
The environment will be updated before starting JupyterLab.

## Expensive cells

Sometimes it can get painful restarting and rerunning a notebook over and over
again.
TODO: More.
